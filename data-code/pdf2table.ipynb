{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year 2015\n",
      "Reg Del\n",
      "specify year in tidy_reg_del\n",
      "specify year in tidy_reg_del\n",
      "Reg Del done\n",
      "Reg Add\n",
      "specify year in tidy_reg_add\n",
      "Reg Add done\n",
      "Nonreg Del\n",
      "Nonreg Del done\n",
      "Nonreg Add\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18106/3138012705.py\u001b[0m in \u001b[0;36m<cell line: 395>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mtidy_tables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtidy_nonreg_del\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpagecontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mwo\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Nonreg Add'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m             \u001b[0mtidy_tables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtidy_nonreg_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpagecontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m         \u001b[0mdouble_check\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwo\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtidy_tables\u001b[0m  \u001b[0;31m# for debug and double check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mtable_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtidy_tables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_18106/3138012705.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mtidy_tables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtidy_nonreg_del\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpagecontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mwo\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Nonreg Add'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m             \u001b[0mtidy_tables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtidy_nonreg_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpagecontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m         \u001b[0mdouble_check\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwo\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtidy_tables\u001b[0m  \u001b[0;31m# for debug and double check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mtable_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtidy_tables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Meta --------------------------------------------------------------------\n",
    "## Title:         Summary of Changes table\n",
    "## Author:        Wonjun Choi\n",
    "## Date Created:  Sept-9-2022\n",
    "## Date Edited:   Oct-4-2022\n",
    "\n",
    "## Dependency: numpy, pandas, tabula\n",
    "#\n",
    "# This code converts Change_of_summary pdf files into csv.\n",
    "# This code only does minimal data cleaning. Extensive data cleaning is\n",
    "# required after merging/building datasets.\n",
    "\n",
    "# Issue found: ID is sometimes integer, sometimes float.\n",
    "#              One ID was character: 653032B in 2011 file.\n",
    "#\n",
    "#              In some years merger&acquisition tables were\n",
    "#              not in the form of dataframe. (discarded)\n",
    "###########################################################################\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabula.io import read_pdf\n",
    "\n",
    "# Hardcoding part\n",
    "import hardcoding\n",
    "pagecontent_all = hardcoding.pagecontent_all\n",
    "\n",
    "# functions\n",
    "def combine_if_key_is_na_from_(where, table, key, columns, join_by=\" \"):\n",
    "    \"\"\"\n",
    "    prototype code for fixing nonreg_add of 2007\n",
    "    \n",
    "    ex) \"below\" (then keep first)\n",
    "    ID | ADDITION             ID |   ADDITION\n",
    "    --------------            ------------------\n",
    "    NA |     I           =>   NA | I AM IRON MAN\n",
    "    NA |    AM                NA |   AM IRON MAN\n",
    "    123|  IRON MAN            123|   IRON MAN\n",
    "    \n",
    "    ex) \"above\"\n",
    "    ID | ADDITION             ID |   ADDITION\n",
    "    --------------            ------------------\n",
    "    123|     I           =>   123|       I\n",
    "    NA |    AM                NA |     I AM\n",
    "    NA |  IRON MAN            NA | I I AM IRON MAN***\n",
    "        \n",
    "    Another code will copy ID from below and drop duplicated.\n",
    "    \n",
    "    This is a bad code... should have been absorbing the above...\n",
    "    \n",
    "    input\n",
    "    =====\n",
    "    where: \"above\" or \"below\"\n",
    "    key: if key is NA, combine columns from {where} if there are multiple NA's\n",
    "         in key in a row, find the first non-NA\n",
    "    join_by: for join_by.join([\"a\", \"b\"])\n",
    "    \"\"\"\n",
    "    t = table.copy()\n",
    "    if type(columns) is str:\n",
    "        columns = [columns]\n",
    "    \n",
    "    for col in columns:\n",
    "        for row in range(len(t)):\n",
    "#            print(row)\n",
    "            if pd.isna(t.loc[row,key]) is True:\n",
    "                combine_list = [t.loc[row,col]]\n",
    "                if where == \"below\":\n",
    "                    row2 = row\n",
    "                    while pd.isna(t.loc[row2,key]) is True:\n",
    "                        combine_list.append(t.loc[row2+1,col])\n",
    "                        row2 = row2 + 1\n",
    "                if where == \"above\":\n",
    "                    row2 = row\n",
    "                    while pd.isna(t.loc[row2,key]) is True:\n",
    "                        combine_list.append(t.loc[row2-1,col])\n",
    "                        #print(t.loc[row2-1,col])\n",
    "                        row2 = row2 - 1\n",
    "                combine_list = [x if not pd.isna(x) else \"\" for x in combine_list]\n",
    "                combine_list = [str(x) if type(x)==float else x for x in combine_list]\n",
    "                if where == \"above\":\n",
    "                    combine_list.reverse()\n",
    "                    if len(combine_list)==3:\n",
    "                        combine_list = combine_list[1:]  # ***see docstring\n",
    "                    \n",
    "                joined_value = join_by.join(combine_list).strip()\n",
    "                t.loc[row,col] = joined_value\n",
    "    return t\n",
    "\n",
    "\n",
    "def fillna_from_(where, table, columns):\n",
    "    \"\"\"    \n",
    "    Fill na by copying from above/below.\n",
    "\n",
    "    ex) where=\"below\":\n",
    "    ID |   CITY               ID |     CITY\n",
    "    --------------            ------------------\n",
    "    NA |    NA         =>     12 |    Atlanta\n",
    "    12 |  Atlanta             12 |    Atlanta\n",
    "\n",
    "    input\n",
    "    =====\n",
    "    where: \"below\", \"above\"\n",
    "    table: pandas dataframe\n",
    "    columns: list of strings\n",
    "    \"\"\"\n",
    "    t = table.copy()\n",
    "    for col in columns:\n",
    "        for row in range(len(t)):\n",
    "            if pd.isna(t.loc[row,col]):\n",
    "                if where == \"above\":\n",
    "                    t.loc[row,col] = t.loc[row-1,col]\n",
    "                elif where == \"below\":\n",
    "                    t.loc[row,col] = t.loc[row+1,col]\n",
    "    # print(\"filled na\")\n",
    "    return t\n",
    "\n",
    "# ====================================================================================\n",
    "def tidy_reg_del(tab):\n",
    "    t = tab.copy()\n",
    "    if year in [2008]:\n",
    "        col = ['REASON FOR DELETION', 'HOSPITAL NAME', 'CITY', 'STATE']\n",
    "        for c in col:\n",
    "            t[c] = t[c].apply(lambda text: text.replace(\"\\r\",\" \"))        \n",
    "    elif year in [2010]:\n",
    "        t = t\n",
    "    elif year in [2011]:\n",
    "        t = combine_if_key_is_na_from_(\"below\",t,'ID','NAME')\n",
    "        t = fillna_from_('below',t,['ID','CITY','STATE','REASON FOR DELETION'])\n",
    "        t.columns = ['ID','HOSPITAL NAME','CITY','STATE','REASON FOR DELETION']\n",
    "    elif year in [2012]:\n",
    "        t = t[1:].reset_index(drop=True)\n",
    "        t.columns = ['ID', 'REASON FOR DELETION', 'HOSPITAL NAME', 'CITY',\n",
    "                     'STATE']\n",
    "        t = combine_if_key_is_na_from_('above',t,'ID',\n",
    "                                       ['REASON FOR DELETION'],join_by=\" \")\n",
    "        t = fillna_from_('above',t,['ID','HOSPITAL NAME','CITY','STATE'])\n",
    "        t = t[~t.ID.duplicated(keep='last')].reset_index(drop=True)\n",
    "    elif year in [2013]:\n",
    "        t.columns = ['ID','HOSPITAL NAME','CITY','STATE','REASON FOR DELETION']\n",
    "        if t.iloc[0,4] == 'DELETION':\n",
    "            t = t[1:].reset_index(drop=True)\n",
    "        t = combine_if_key_is_na_from_(\"above\", t, 'ID', ['REASON FOR DELETION','HOSPITAL NAME'], join_by=' ')\n",
    "        t = fillna_from_(\"above\",t, columns=['ID','CITY','STATE'])\n",
    "        t = t[~t.ID.duplicated(keep='last')].reset_index(drop=True)\n",
    "    elif year in [2014]:\n",
    "        if t.columns[0] != 'ID':\n",
    "            t = t.T.reset_index().T.reset_index(drop=True)\n",
    "        adddel = 'DELETION'\n",
    "        if t.columns[2] == 'Unnamed: 0':\n",
    "            t.columns = ['ID','HOSPITAL NAME','CITY','STATE','REASON FOR '+adddel]\n",
    "            if t.iloc[0,4] == adddel:\n",
    "                t = t[1:].reset_index(drop=True)\n",
    "            t = combine_if_key_is_na_from_(\"above\", t, 'ID',['REASON FOR '+adddel,'HOSPITAL NAME'], join_by=' ')\n",
    "            # only last word of CITY is valid...\n",
    "            t['CITY'] = t['HOSPITAL NAME'].apply(lambda t: t.split(\" \")[-1])\n",
    "            t['HOSPITAL NAME'] = t['HOSPITAL NAME'].apply(lambda t: \" \".join(t.split(\" \")[:-1]))\n",
    "        else:\n",
    "            t.columns = ['ID','HOSPITAL NAME','CITY','STATE','REASON FOR '+adddel]\n",
    "            if t.iloc[0,4] == adddel:\n",
    "                t = t[1:].reset_index(drop=True)\n",
    "            t = combine_if_key_is_na_from_(\"above\", t, 'ID',['REASON FOR '+adddel,'HOSPITAL NAME'], join_by=' ')\n",
    "\n",
    "        t = fillna_from_(\"above\",t, columns=['ID','CITY','STATE'])\n",
    "        for col in ['REASON FOR '+adddel,'HOSPITAL NAME', 'CITY']:\n",
    "            t[col] = t[col].apply(lambda x: x.replace('\\r',' '))\n",
    "        t = t[~t.ID.duplicated(keep='last')].reset_index(drop=True)\n",
    "        \n",
    "    else:\n",
    "        print(\"specify year in tidy_reg_del\")\n",
    "    \n",
    "    return t\n",
    "\n",
    "def tidy_reg_add(tab):\n",
    "    t = tab.copy()\n",
    "    if year in [2012]:\n",
    "        if t.iloc[0,1] == 'ADDITION':\n",
    "            t = t[1:].reset_index(drop=True)\n",
    "        t.columns = ['ID','REASON FOR ADDITION','HOSPITAL NAME','CITY','STATE']\n",
    "        t = combine_if_key_is_na_from_(\"above\", t, 'ID', ['REASON FOR ADDITION','HOSPITAL NAME'], join_by=' ')\n",
    "        t = fillna_from_(\"above\",t, columns=['ID','CITY','STATE'])\n",
    "        for col in ['REASON FOR ADDITION','HOSPITAL NAME', 'CITY']:\n",
    "            t[col] = t[col].apply(lambda x: x.replace('\\r',' '))\n",
    "        t = t[~t.ID.duplicated(keep='last')].reset_index(drop=True)\n",
    "    elif year in [2013]:\n",
    "        adddel = 'ADDITION'\n",
    "        t.columns = ['ID','HOSPITAL NAME','CITY','STATE','REASON FOR '+adddel]\n",
    "        if t.iloc[0,4] == adddel:\n",
    "            t = t[1:].reset_index(drop=True)\n",
    "        t = combine_if_key_is_na_from_(\"above\", t, 'ID', ['REASON FOR '+adddel,'HOSPITAL NAME'], join_by=' ')\n",
    "        t = fillna_from_(\"above\",t, columns=['ID','CITY','STATE'])\n",
    "        t = t[~t.ID.duplicated(keep='last')].reset_index(drop=True)\n",
    "    elif year in [2014]:\n",
    "        adddel = 'ADDITION'\n",
    "        t.columns = ['ID','HOSPITAL NAME','CITY','STATE','REASON FOR '+adddel]\n",
    "        if t.iloc[0,4] == adddel:\n",
    "            t = t[1:].reset_index(drop=True)\n",
    "        t = combine_if_key_is_na_from_(\"above\", t, 'ID',['REASON FOR '+adddel,'HOSPITAL NAME'], join_by=' ')\n",
    "        t = fillna_from_(\"above\",t, columns=['ID','CITY','STATE'])\n",
    "\n",
    "    else:\n",
    "        print(\"specify year in tidy_reg_add\")\n",
    "    return t\n",
    "\n",
    "def tidy_nonreg_del(tab):\n",
    "    t = tab.copy()\n",
    "    if year in [2007]:\n",
    "        t = combine_if_key_is_na_from_(\"below\", t, \"ID\", \"REASON FOR DELETION\")\n",
    "        t = fillna_from_(\"below\", t, ['ID','HOSPITAL NAME', 'CITY', 'STATE'])\n",
    "        t = t.loc[~t.duplicated('ID')].reset_index().drop('index',axis=1)\n",
    "    \n",
    "    elif year in [2008]:\n",
    "        col = ['REASON FOR DELETION', 'HOSPITAL NAME', 'CITY', 'STATE']\n",
    "        for c in col:\n",
    "            t[c] = t[c].apply(lambda text: text.replace(\"\\r\",\" \"))\n",
    "    \n",
    "    elif year in [2009]:\n",
    "        t = combine_if_key_is_na_from_(\"below\", t, \"ID\", [\"REASON FOR DELETION\",\"HOSPITAL NAME\"])\n",
    "        t = fillna_from_(\"below\", t, [\"ID\", \"CITY\", \"STATE\"])\n",
    "        t = t.loc[~t.duplicated('ID')].reset_index().drop('index',axis=1)\n",
    "        \n",
    "    elif year in [2010]:\n",
    "        t['CITY'] = t['HOSPITAL NAME CITY'].apply(lambda x: x.split(\" \")[-1])\n",
    "        t['HOSPITAL NAME'] = t['HOSPITAL NAME CITY'].apply(lambda x: \" \".join(x.split(\" \")[:-1]))\n",
    "        t = t.drop(columns=['HOSPITAL NAME CITY'])\n",
    "        \n",
    "    elif year in [2012]:\n",
    "        t.columns = ['ID','REASON FOR DELETION','HOSPITAL NAME','CITY','STATE']\n",
    "\n",
    "        if t.iloc[0,1] == 'DELETION':\n",
    "            t = t[1:].reset_index(drop=True)\n",
    "        t = combine_if_key_is_na_from_(\"above\", t, 'ID', ['REASON FOR DELETION','HOSPITAL NAME'], join_by=' ')\n",
    "        t = fillna_from_(\"above\",t, columns=['ID','CITY','STATE'])\n",
    "        for col in ['REASON FOR DELETION','HOSPITAL NAME', 'CITY']:\n",
    "            t[col] = t[col].apply(lambda x: x.replace('\\r',' '))\n",
    "        t = t[~t.ID.duplicated(keep='last')].reset_index(drop=True)\n",
    "    elif year in [2013]:\n",
    "        adddel = 'DELETION'\n",
    "        t.columns = ['ID','HOSPITAL NAME','CITY','STATE','REASON FOR '+adddel]\n",
    "        if t.iloc[0,4] == adddel:\n",
    "            t = t[1:].reset_index(drop=True)\n",
    "        t = combine_if_key_is_na_from_(\"above\", t, 'ID', ['REASON FOR '+adddel,'HOSPITAL NAME'], join_by=' ')\n",
    "        t = fillna_from_(\"above\",t, columns=['ID','CITY','STATE'])\n",
    "        for col in ['REASON FOR '+adddel,'HOSPITAL NAME', 'CITY']:\n",
    "            t[col] = t[col].apply(lambda x: x.replace('\\r',' '))\n",
    "        t = t[~t.ID.duplicated(keep='last')].reset_index(drop=True)\n",
    "    elif year in [2014]:\n",
    "        if t.columns[0] != 'ID':\n",
    "            t = t.T.reset_index().T.reset_index(drop=True)\n",
    "        adddel = 'DELETION'\n",
    "        if t.columns[1] == 'Unnamed: 0':\n",
    "            t = t.drop(columns='NAME')\n",
    "        t.columns = ['ID','HOSPITAL NAME','CITY','STATE','REASON FOR '+adddel]\n",
    "        t = combine_if_key_is_na_from_(\"above\", t, 'ID',\n",
    "                                       ['REASON FOR '+adddel,'HOSPITAL NAME'],\n",
    "                                       join_by=' ')\n",
    "        t = fillna_from_(\"above\",t, columns=['ID','CITY','STATE'])\n",
    "        for col in ['REASON FOR '+adddel,'HOSPITAL NAME', 'CITY']:\n",
    "            t[col] = t[col].apply(lambda x: x.replace('\\r',' ') \n",
    "                                  if pd.isna(x)==False else x)\n",
    "        t = t[~t.ID.duplicated(keep='last')].reset_index(drop=True)        \n",
    "    \n",
    "    return t\n",
    "\n",
    "def tidy_nonreg_add(tab):\n",
    "    \"\"\"\n",
    "    dd\n",
    "    \"\"\"\n",
    "    t = tab.copy()\n",
    "    if year in [2007]:  # year is a global variable. consider f(tab,year=year)\n",
    "        t.columns = t.iloc[0]\n",
    "        t = t[1:].reset_index(drop=True)\n",
    "        t = combine_if_key_is_na_from_(\"below\", t, \"ID\", \"ADDITION\")\n",
    "        t = fillna_from_(\"below\", t, ['ID','HOSPITAL NAME','CITY','STATE'])\n",
    "        t = t.loc[~t.duplicated('ID')].reset_index().drop('index', axis=1)\n",
    "        t.columns = ['ID', 'REASON FOR ADDITION', 'HOSPITAL NAME', 'CITY', 'STATE']\n",
    "        \n",
    "    elif year in [2008,2009]:\n",
    "        t.columns = ['ID', 'REASON FOR ADDITION', 'HOSPITAL NAME', 'CITY', 'STATE']\n",
    "        t['REASON FOR ADDITION'] = t['REASON FOR ADDITION'].apply(lambda x: x.replace(\"\\r\",\" \"))\n",
    "\n",
    "        if year == 2009:\n",
    "            t = combine_if_key_is_na_from_(\"below\", t, \"ID\", \"REASON FOR ADDITION\")\n",
    "            t = fillna_from_(\"below\", t, [\"ID\", \"CITY\", \"STATE\", \"HOSPITAL NAME\"])\n",
    "            t = t.loc[~t.duplicated('ID')].reset_index().drop('index',axis=1)\n",
    "            t = t.drop(t[t.ID == \"ID\"].index)\n",
    "            \n",
    "    elif year in [2010]:\n",
    "        t.columns = ['ID', 'REASON FOR ADDITION', 'HOSPITAL NAME', 'CITY', 'STATE']\n",
    "        t = t[1:].reset_index(drop=True)\n",
    "        def f(text):\n",
    "            name = text.split('Newly Added')[-1].split('Status changed to')[-1]\n",
    "            if name == 'nonregistered':\n",
    "                reason, name = 'nonregistered', np.nan\n",
    "                return reason, name\n",
    "            elif len(name) == 0:\n",
    "                reason, name = 'no thx', 'no thx'  # second page is ok...\n",
    "                return reason, name\n",
    "            else:\n",
    "                reason = text.split(name)[0]\n",
    "                name = name[1:]  # remove blank\n",
    "                return reason, name\n",
    "        for row in range(len(t)):\n",
    "            reason, name = f(t.loc[row, 'REASON FOR ADDITION'])\n",
    "            if not reason=='no thx':\n",
    "                t.loc[row, 'REASON FOR ADDITION'] = reason\n",
    "                t.loc[row, 'HOSPITAL NAME'] = name            \n",
    "        t = combine_if_key_is_na_from_(\"above\", t, \"ID\", \"REASON FOR ADDITION\")\n",
    "        t = fillna_from_(\"above\",t,[\"ID\",\"HOSPITAL NAME\", \"CITY\", \"STATE\"])\n",
    "        \n",
    "    elif year in [2011]:\n",
    "        t.columns = ['ID', 'HOSPITAL NAME', 'CITY', 'STATE', 'REASON FOR ADDITION']\n",
    "        \n",
    "    elif year in [2012]:\n",
    "        t.columns = ['ID','REASON FOR ADDITION','HOSPITAL NAME','CITY','STATE']\n",
    "        if t.iloc[0,1] == 'ADDITION':\n",
    "            t = t[1:].reset_index(drop=True)\n",
    "        t = combine_if_key_is_na_from_(\"above\", t, 'ID', ['REASON FOR ADDITION','HOSPITAL NAME'], join_by=' ')\n",
    "        t = fillna_from_(\"above\",t, columns=['ID','CITY','STATE'])\n",
    "        for col in ['REASON FOR ADDITION','HOSPITAL NAME', 'CITY']:\n",
    "            t[col] = t[col].apply(lambda x: x.replace('\\r',' '))\n",
    "        t = t[~t.ID.duplicated(keep='last')].reset_index(drop=True)\n",
    "        \n",
    "    elif year in [2013]:\n",
    "        if t.columns[0] != 'ID':\n",
    "            t = t.T.reset_index().T.reset_index(drop=True)\n",
    "        adddel = 'ADDITION'\n",
    "        t.columns = ['ID','HOSPITAL NAME','CITY','STATE','REASON FOR '+adddel]\n",
    "        if t.iloc[0,4] == adddel:\n",
    "            t = t[1:].reset_index(drop=True)\n",
    "        t = combine_if_key_is_na_from_(\"above\", t, 'ID',['REASON FOR '+adddel,'HOSPITAL NAME'], join_by=' ')\n",
    "        t = fillna_from_(\"above\",t, columns=['ID','CITY','STATE'])\n",
    "        for col in ['REASON FOR '+adddel,'HOSPITAL NAME', 'CITY']:\n",
    "            t[col] = t[col].apply(lambda x: x.replace('\\r',' '))\n",
    "        t = t[~t.ID.duplicated(keep='last')].reset_index(drop=True)\\\n",
    "        \n",
    "    elif year in [2014]:\n",
    "        adddel = 'ADDITION'\n",
    "        if t.columns[1] == 'Unnamed: 0':\n",
    "            t = t.drop(columns='NAME')\n",
    "        t.columns = ['ID','HOSPITAL NAME','CITY','STATE','REASON FOR '+adddel]\n",
    "      \n",
    "    return t\n",
    "    \n",
    "def tidy_merger(tab):\n",
    "    t = tab.copy()\n",
    "    \n",
    "    if year in [2007]:\n",
    "        t = t[1:].reset_index(drop=True)\n",
    "\n",
    "        t['Unnamed: 0'] = t['ID NAME'].apply(lambda idname: ' '.join(idname.split(' ')[1:]) \n",
    "                                             if pd.isna(idname)==False else np.nan)\n",
    "        t['ID NAME'] = t['ID NAME'].apply(lambda idname: idname.split(' ')[0] \n",
    "                                          if pd.isna(idname)==False else np.nan)\n",
    "\n",
    "        t['Unnamed: 1'] = t['MERGER MERGED NAME'].apply(lambda mmn: ' '.join(mmn.split(' ')[1:]) \n",
    "                                                        if pd.isna(mmn)==False else np.nan)\n",
    "        t['MERGER MERGED NAME'] = t['MERGER MERGED NAME'].apply(lambda mmn: mmn.split(' ')[0] \n",
    "                                                                if pd.isna(mmn)==False else np.nan)\n",
    "\n",
    "        t['MERGED STATE'] = t['MERGED CITY MERGED'].apply(lambda mcm: mcm.split(' ')[-1] \n",
    "                                                          if pd.isna(mcm)==False else np.nan)\n",
    "        t['MERGED CITY MERGED'] = t['MERGED CITY MERGED'].apply(lambda mcm:' '.join(mcm.split(' ')[:-1]) \n",
    "                                                                if pd.isna(mcm)==False else np.nan)\n",
    "\n",
    "        t = t.rename(columns = {'ID NAME': 'ID', 'Unnamed: 0': 'NAME',\n",
    "                                'MERGER MERGED NAME': 'MERGER RESULT ID',\n",
    "                           'Unnamed: 1': 'MERGED NAME', 'MERGED CITY MERGED': 'MERGED CITY'})\n",
    "        t = t.reset_index().drop(['index'],axis=1)\n",
    "\n",
    "        t = fillna_from_(\"above\", t, ['MERGER RESULT ID', 'MERGED NAME', 'MERGED CITY', \n",
    "                                      'MERGED STATE'])\n",
    "        \n",
    "    elif year in [2008]:\n",
    "        t['Unnamed: 0'] = t['ID HOSPITAL NAME'].apply(lambda idname: ' '.join(idname.split(' ')[1:]) \n",
    "                                                      if pd.isna(idname)==False else np.nan)\n",
    "        t['ID HOSPITAL NAME'] = t['ID HOSPITAL NAME'].apply(lambda idname: idname.split(' ')[0] \n",
    "                                                            if pd.isna(idname)==False else np.nan)\n",
    "        \n",
    "    elif year in [2009]:\n",
    "        t.columns = [x.replace(\"\\r\",\" \") for x in t.columns]\n",
    "        t = fillna_from_(\"above\", t, ['MERGER RESULT ID', 'MERGED NAME', 'MERGED CITY', \n",
    "                                      'MERGED STATE'])\n",
    "\n",
    "    return t\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "# make pdf tables into csv\n",
    "\n",
    "dir_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "outfile_base = os.path.join(dir_root, 'data','temp')\n",
    "\n",
    "double_check = {}\n",
    "\n",
    "for year in range(2015,2016):\n",
    "    print('year {}'.format(year))\n",
    "    file_pdf = os.path.join(dir_root,'data','input','AHA FY {}'.format(year),\n",
    "                            *hardcoding.filenames[year])\n",
    "    tables = read_pdf(file_pdf, pages='all', multiple_tables=True)\n",
    "    \n",
    "    pagecontent = pagecontent_all[str(year)]\n",
    "    \n",
    "    workingon = [\"Reg Del\",\"Reg Add\",\"Nonreg Del\",\"Nonreg Add\"]\n",
    "    for wo in workingon:\n",
    "        print(wo)\n",
    "        if wo == 'Reg Del':  # modify this if syntax later\n",
    "            tidy_tables = [tidy_reg_del(tables[page]) for page in pagecontent[wo]]\n",
    "        elif wo == 'Reg Add':\n",
    "            tidy_tables = [tidy_reg_add(tables[page]) for page in pagecontent[wo]]\n",
    "        elif wo == 'Nonreg Del':\n",
    "            tidy_tables = [tidy_nonreg_del(tables[page]) for page in pagecontent[wo]]\n",
    "        elif wo == 'Nonreg Add':\n",
    "            tidy_tables = [tidy_nonreg_add(tables[page]) for page in pagecontent[wo]]\n",
    "        double_check[wo] = tidy_tables  # for debug and double check\n",
    "        table_csv = pd.concat(tidy_tables, ignore_index=True)\n",
    "        table_csv = table_csv.dropna()\n",
    "        table_csv.to_csv(os.path.join(outfile_base,\n",
    "                                      'change_'+wo+'_{}.csv'.format(year)),\n",
    "                        header=True, index=False)\n",
    "        print(wo+\" done\")\n",
    "        \n",
    "    # if year in [2008,2010]:\n",
    "    #     print(\"Merger and Acquisitions {} table is a disaster\".format(year))\n",
    "    #     pass\n",
    "    # else:\n",
    "    #     table_merger = pd.concat([tidy_merger(tables[page])\n",
    "    #                               for page in pagecontent[\"Mergers and Acquisitions\"]],\n",
    "    #                               ignore_index=True)\n",
    "    #     table_merger.to_csv(os.path.join(outfile_base,'change_merger_{}.csv'.format(year)),\n",
    "    #                         header=True, index=False)\n",
    "    # print(\"merger done\")\n",
    "    \n",
    "print(\"I'm Done!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double_check[\"Reg Del\"][3]\n",
    "# double_check[\"Reg Add\"][0]\n",
    "# double_check[\"Nonreg Del\"][1]\n",
    "double_check[\"Nonreg Add\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pdf = os.path.join(dir_root,'data','input','AHA FY {}'.format(year),\n",
    "                            *hardcoding.filenames[year])\n",
    "tables = read_pdf(file_pdf, pages='all', multiple_tables=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Reg Del': [1, 2],\n",
       " 'Reg Add': [3],\n",
       " 'Nonreg Del': [5],\n",
       " 'Nonreg Add': [6, 7],\n",
       " 'Mergers and Acquisitions': []}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pagecontent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>HOSPITAL NAME</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>REASON FOR DELETION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>and Parent Organization for Merged Entities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6110173.0</td>\n",
       "      <td>Parkview Adventist Medical Center Brunswick</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ME</td>\n",
       "      <td>Ambulatory Care Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6141800.0</td>\n",
       "      <td>Spaulding Hospital for Continuing Medical Care...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MA</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Merged into 6212925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6210770.0</td>\n",
       "      <td>NYU Lutheran Brooklyn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>NYU Lagone Medical Center - New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>6740041.0</td>\n",
       "      <td>Central Texas Hospital Cameron</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TX</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>6740252.0</td>\n",
       "      <td>East Texas Medical Center-Gilmer Gilmer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TX</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>6740275.0</td>\n",
       "      <td>Kindred Hospital North Houston Houston</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TX</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>6740278.0</td>\n",
       "      <td>Kindred Hospital East Houston Channelview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TX</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>6740348.0</td>\n",
       "      <td>Regency Hospital of Fort Worth Fort Worth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TX</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                      HOSPITAL NAME  CITY STATE  \\\n",
       "0         NaN                                                NaN   NaN   NaN   \n",
       "1   6110173.0        Parkview Adventist Medical Center Brunswick   NaN    ME   \n",
       "2   6141800.0  Spaulding Hospital for Continuing Medical Care...   NaN    MA   \n",
       "3         NaN                                                NaN   NaN   NaN   \n",
       "4   6210770.0                              NYU Lutheran Brooklyn   NaN    NY   \n",
       "..        ...                                                ...   ...   ...   \n",
       "58  6740041.0                     Central Texas Hospital Cameron   NaN    TX   \n",
       "59  6740252.0            East Texas Medical Center-Gilmer Gilmer   NaN    TX   \n",
       "60  6740275.0             Kindred Hospital North Houston Houston   NaN    TX   \n",
       "61  6740278.0          Kindred Hospital East Houston Channelview   NaN    TX   \n",
       "62  6740348.0          Regency Hospital of Fort Worth Fort Worth   NaN    TX   \n",
       "\n",
       "                            REASON FOR DELETION  \n",
       "0   and Parent Organization for Merged Entities  \n",
       "1                        Ambulatory Care Center  \n",
       "2                                        Closed  \n",
       "3                           Merged into 6212925  \n",
       "4      NYU Lagone Medical Center - New York, NY  \n",
       "..                                          ...  \n",
       "58                                       Closed  \n",
       "59                                       Closed  \n",
       "60                                       Closed  \n",
       "61                                       Closed  \n",
       "62                                       Closed  \n",
       "\n",
       "[63 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tidy snippet\n",
    "t = tables[1].copy()\n",
    "\n",
    "# if t.columns[0] != 'ID':\n",
    "#     t = t.T.reset_index().T.reset_index(drop=True)\n",
    "\n",
    "adddel = 'DELETION'\n",
    "\n",
    "# idiosyncratic\n",
    "# if t.columns[2] == 'Unnamed: 0':\n",
    "#     t.columns = ['ID','HOSPITAL NAME','CITY','STATE','REASON FOR '+adddel]\n",
    "#     if t.iloc[0,4] == adddel:\n",
    "#         t = t[1:].reset_index(drop=True)\n",
    "#     t = combine_if_key_is_na_from_(\"above\", t, 'ID',['REASON FOR '+adddel,'HOSPITAL NAME'], join_by=' ')\n",
    "#     # only last word of CITY is valid...\n",
    "#     t['CITY'] = t['HOSPITAL NAME'].apply(lambda t: t.split(\" \")[-1])\n",
    "#     t['HOSPITAL NAME'] = t['HOSPITAL NAME'].apply(lambda t: \" \".join(t.split(\" \")[:-1]))\n",
    "if t.columns[1] == 'Unnamed: 0':\n",
    "    t = t.drop(columns='NAME')\n",
    "#=====\n",
    "t.columns = ['ID','HOSPITAL NAME','CITY','STATE','REASON FOR '+adddel]\n",
    "# if t.iloc[0,4] == adddel:\n",
    "#     t = t[1:].reset_index(drop=True)\n",
    "    \n",
    "# t = combine_if_key_is_na_from_(\"above\", t, 'ID',\n",
    "#                                ['REASON FOR '+adddel,'HOSPITAL NAME'],\n",
    "#                                join_by=' ')\n",
    "# t = fillna_from_(\"above\",t, columns=['ID','CITY','STATE'])\n",
    "# for col in ['REASON FOR '+adddel,'HOSPITAL NAME', 'CITY']:\n",
    "#     t[col] = t[col].apply(lambda x: x.replace('\\r',' ') \n",
    "#                           if pd.isna(x)==False else x)\n",
    "# t = t[~t.ID.duplicated(keep='last')].reset_index(drop=True)\n",
    "\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?combine_if_key_is_na_from_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        t.columns = ['ID', 'REASON FOR ADDITION', 'HOSPITAL NAME', 'CITY', 'STATE']\n",
    "        t = t[1:].reset_index(drop=True)\n",
    "        def f(text):\n",
    "            name = text.split('Newly Added')[-1].split('Status changed to')[-1]\n",
    "            if name == 'nonregistered':\n",
    "                reason, name = 'nonregistered', ''\n",
    "                return reason, name\n",
    "            elif len(name) == 0:\n",
    "                reason, name = 'no thx', 'no thx'  # second page is ok...\n",
    "                return reason, name\n",
    "            else:\n",
    "                reason = text.split(name)[0]\n",
    "                name = name[1:]  # remove blank\n",
    "                return reason, name\n",
    "        t['HOSPITAL NAME'] = t['REASON FOR ADDITION'].apply(lambda x: f(x)[1] if (f(x)[1] is not 'no thx') else x)\n",
    "        t['REASON FOR ADDITION'] = t['REASON FOR ADDITION'].apply(lambda x: f(x)[0] if (f(x)[0] is not 'no thx') else x)\n",
    "        t = combine_if_key_is_na_from_(\"below\", t, \"ID\", \"REASON FOR ADDITION\")\n",
    "        t = fillna_from_(\"above\",t,[\"ID\",\"HOSPITAL NAME\", \"CITY\", \"STATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(text):\n",
    "        name = text.split('Newly Added')[-1].split('Status changed to')[-1]\n",
    "        if name == 'nonregistered':\n",
    "            reason, name = 'nonregistered', np.nan\n",
    "            return reason, name\n",
    "        elif len(name) == 0:\n",
    "            reason, name = 'no thx', 'no thx'  # second page is ok...\n",
    "            return reason, name\n",
    "        else:\n",
    "            reason = text.split(name)[0]\n",
    "            name = name[1:]  # remove blank\n",
    "            return reason, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = [tables[page] for page in pagecontent[\"Nonreg Add\"]]\n",
    "tt = asd[1].copy()\n",
    "tt.columns = ['ID', 'REASON FOR ADDITION', 'HOSPITAL NAME', 'CITY', 'STATE']\n",
    "tt = tt[1:].reset_index(drop=True)\n",
    "tt['HOSPITAL NAME'] = tt['REASON FOR ADDITION'].apply(lambda x: f(x)[1] if (f(x)[1] is not 'no thx') else x)\n",
    "# tt['REASON FOR ADDITION'] = tt['REASON FOR ADDITION'].apply(lambda x: f(x)[0] if (f(x)[0] is not 'no thx') else x)\n",
    "#tt = combine_if_key_is_na_from_(\"above\", tt, \"ID\", \"REASON FOR ADDITION\")\n",
    "\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_reg_del[0:50]\n",
    "# table_reg_del[51:100]\n",
    "# table_reg_del[101:]\n",
    "\n",
    "table_reg_add[0:50]\n",
    "# table_reg_add[51:100]\n",
    "# table_reg_add[101:]\n",
    "\n",
    "# table_nonreg_del[0:50]\n",
    "# table_nonreg_del[51:100]\n",
    "# table_nonreg_del[101:]\n",
    "\n",
    "# table_nonreg_add[0:50]\n",
    "# table_nonreg_add[51:100]\n",
    "# table_nonreg_add[101:]\n",
    "\n",
    "#table_merger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_nonreg_del.loc[3,'HOSPITAL NAME'].replace(\"\\r\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_reg_del.loc[59,'ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagecontent[\"Nonreg Add\"]\n",
    "tables[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
